# -*- coding: utf-8 -*-
"""pix2pix.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/19AguYkX-qFd15rWldrOMRj0ti_BXStNl
"""


import os
from PIL import Image
import numpy as np
import tensorflow as tf
import pathlib
import time
import datetime
from matplotlib import pyplot as plt
from IPython import display
	

############################################SETUP#####################################################

# The facade training set consist of 400 images
BUFFER_SIZE = 2603
# The batch size of 1 produced better results for the U-Net in the original pix2pix experiment
BATCH_SIZE = 1
# Each image is 256x256 in size
IMG_WIDTH = 512
IMG_HEIGHT = 512


def get_range(img=None,img_path=None):# Afficher la plage des valeurs des pixels
  if img == None and img_path != None:
    sample_image = tf.io.read_file(img_path)
    sample_image = tf.io.decode_jpeg(sample_image)
    sample_image = np.array(sample_image)
    min_pixel_value = sample_image_msk.min()
    max_pixel_value = sample_image_msk.max()
    print(f"Plage des valeurs des pixels : [{min_pixel_value}, {max_pixel_value}]")
  elif img_path == None and img != None:
    img = np.array(img)
    min_pixel_value = img.min()
    max_pixel_value = img.max()
    print(f"Plage des valeurs des pixels : [{min_pixel_value}, {max_pixel_value}]")


def load(input_image_file, real_image_file):
  """
  Read and decode two image files from disk:
  - one for the input image (a real building facade)
  - one for the real image (an architecture label)
  """
  # Read and decode the input image file to a uint8 tensor
  input_image = tf.io.read_file(input_image_file)
  input_image = tf.io.decode_png(input_image)

  # Read and decode the real image file to a uint8 tensor
  real_image = tf.io.read_file(real_image_file)
  real_image = tf.io.decode_png(real_image)

  # Convert both images to float32 tensors
  input_image = tf.cast(input_image, tf.float32)
  real_image = tf.cast(real_image, tf.float32)

  return input_image, real_image


def resize(input_image, real_image, height, width):
  input_image = tf.image.resize(input_image, [height, width],
                                method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)
  real_image = tf.image.resize(real_image, [height, width],
                               method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)

  return input_image, real_image

def normalize(input_image, real_image):
    # Normalizing input_image from range [0, 4] to [-1, 1]
    input_image = (input_image / 2.0) - 1
    # Normalizing real_image from range [44, 255] to [-1, 1]
    real_image = (real_image - 44) / (255 - 44) * 2 - 1

    return input_image, real_image

def random_crop(input_image, real_image):

  input_image = tf.image.grayscale_to_rgb(input_image)
  real_image = tf.image.grayscale_to_rgb(real_image)

  print("INPUT, REAL SHAPES: ", input_image.shape, " --- ", real_image.shape)

  stacked_image = tf.stack([input_image, real_image], axis=0)

  cropped_image = tf.image.random_crop(

      stacked_image, size=[2, IMG_HEIGHT, IMG_WIDTH, 3]) ###PUT 1 or 3 ???

  return cropped_image[0], cropped_image[1]

@tf.function()
def random_jitter(input_image, real_image):
  # Resizing to 542x542
  input_image, real_image = resize(input_image, real_image, 542, 542)
  # Random cropping back to 256x256
  input_image, real_image = random_crop(input_image, real_image)
  if tf.random.uniform(()) > 0.5:
    # Random mirroring
    input_image = tf.image.flip_left_right(input_image)
    real_image = tf.image.flip_left_right(real_image)

  return input_image, real_image

def file_exists(filepath):
    if tf.io.gfile.exists(filepath):
        return filepath
    else:
        raise FileNotFoundError(f"File {filepath} does not exist.")

def load_image_train(reel_image_path):
  image_file = tf.strings.split(reel_image_path, os.sep)[-1]
  image_file = tf.strings.regex_replace(image_file, '.png', '')
  input_image_path = tf.strings.join(['../data/ade20k/','annotations/training/', image_file, '_lung.png'])
  input_image, real_image = load(input_image_path,reel_image_path)
  input_image, real_image = random_jitter(input_image, real_image)
  input_image, real_image = normalize(input_image, real_image)
  return input_image, real_image

def load_image_val(reel_image_path):
  image_file = tf.strings.split(reel_image_path, os.sep)[-1]
  image_file = tf.strings.regex_replace(image_file, '.png', '')
  input_image_path = tf.strings.join(['../data/ade20k/','annotations/validation/', image_file, '_lung.png'])
  input_image, real_image = load(input_image_path,reel_image_path)
  input_image, real_image = random_jitter(input_image, real_image)
  input_image, real_image = normalize(input_image, real_image)
  return input_image, real_image

#################################CONSTRUCTION_DATASETS####################################

reel_training_image_paths = os.listdir('../data/ade20k/images/training/')
reel_training_image_paths = ['../data/ade20k/images/training/' + path for path in reel_training_image_paths]
reel_validation_image_paths = os.listdir('../data/ade20k/images/validation/')
reel_validation_image_paths = ['../data/ade20k/images/validation/' + path for path in reel_validation_image_paths]

reel_training_image_paths = tf.data.Dataset.from_tensor_slices(reel_training_image_paths)
reel_validation_image_paths = tf.data.Dataset.from_tensor_slices(reel_validation_image_paths)


train_dataset = reel_training_image_paths.map(lambda reel_training_image_paths: load_image_train(reel_training_image_paths),
                                       num_parallel_calls=tf.data.experimental.AUTOTUNE)
train_dataset = train_dataset.shuffle(buffer_size=1000).batch(32).prefetch(buffer_size=tf.data.experimental.AUTOTUNE)

val_dataset = reel_validation_image_paths.map(lambda reel_validation_image_paths: load_image_val(reel_validation_image_paths),
                                       num_parallel_calls=tf.data.experimental.AUTOTUNE)
val_dataset = val_dataset.shuffle(buffer_size=1000).batch(32).prefetch(buffer_size=tf.data.experimental.AUTOTUNE)

################################MODEL CREATION###########################

OUTPUT_CHANNELS = 3

def downsample(filters, size, apply_batchnorm=True):
  initializer = tf.random_normal_initializer(0., 0.02)

  result = tf.keras.Sequential()
  result.add(
      tf.keras.layers.Conv2D(filters, size, strides=2, padding='same',
                             kernel_initializer=initializer, use_bias=False))

  if apply_batchnorm:
    result.add(tf.keras.layers.BatchNormalization())

  result.add(tf.keras.layers.LeakyReLU())

  return result


def upsample(filters, size, apply_dropout=False):
  initializer = tf.random_normal_initializer(0., 0.02)

  result = tf.keras.Sequential()
  result.add(
    tf.keras.layers.Conv2DTranspose(filters, size, strides=2,
                                    padding='same',
                                    kernel_initializer=initializer,
                                    use_bias=False))

  result.add(tf.keras.layers.BatchNormalization())

  if apply_dropout:
      result.add(tf.keras.layers.Dropout(0.5))

  result.add(tf.keras.layers.ReLU())

  return result


def Generator():
  inputs = tf.keras.layers.Input(shape=[IMG_HEIGHT, IMG_WIDTH, 3]) #maybe put RGB instead of grayscale

  down_stack = [
    downsample(64, 4, apply_batchnorm=False),  # (batch_size, 128, 128, 64)
    downsample(128, 4),  # (batch_size, 64, 64, 128)
    downsample(256, 4),  # (batch_size, 32, 32, 256)
    downsample(512, 4),  # (batch_size, 16, 16, 512)
    downsample(512, 4),  # (batch_size, 8, 8, 512)
    downsample(512, 4),  # (batch_size, 4, 4, 512)
    downsample(512, 4),  # (batch_size, 2, 2, 512)
    downsample(512, 4),  # (batch_size, 1, 1, 512)
  ]

  up_stack = [
    upsample(512, 4, apply_dropout=True),  # (batch_size, 2, 2, 1024)
    upsample(512, 4, apply_dropout=True),  # (batch_size, 4, 4, 1024)
    upsample(512, 4, apply_dropout=True),  # (batch_size, 8, 8, 1024)
    upsample(512, 4),  # (batch_size, 16, 16, 1024)
    upsample(256, 4),  # (batch_size, 32, 32, 512)
    upsample(128, 4),  # (batch_size, 64, 64, 256)
    upsample(64, 4),  # (batch_size, 128, 128, 128)
  ]

  initializer = tf.random_normal_initializer(0., 0.02)
  last = tf.keras.layers.Conv2DTranspose(OUTPUT_CHANNELS, 4,
                                         strides=2,
                                         padding='same',
                                         kernel_initializer=initializer,
                                         activation='tanh')  # (batch_size, 256, 256, 3)

  x = inputs

  # Downsampling through the model
  skips = []
  for down in down_stack:
    x = down(x)
    skips.append(x)

  skips = reversed(skips[:-1])

  # Upsampling and establishing the skip connections
  for up, skip in zip(up_stack, skips):
    x = up(x)
    x = tf.keras.layers.Concatenate()([x, skip])

  x = last(x)

  return tf.keras.Model(inputs=inputs, outputs=x)

generator = Generator()



"""###PERTE"""

LAMBDA = 100
loss_object = tf.keras.losses.BinaryCrossentropy(from_logits=True)

def generator_loss(disc_generated_output, gen_output, target):
  gan_loss = loss_object(tf.ones_like(disc_generated_output), disc_generated_output)

  # Mean absolute error
  l1_loss = tf.reduce_mean(tf.abs(target - gen_output))

  total_gen_loss = gan_loss + (LAMBDA * l1_loss)

  return total_gen_loss, gan_loss, l1_loss

"""###DISCRIMINATEUR"""

def Discriminator():
  initializer = tf.random_normal_initializer(0., 0.02)

  inp = tf.keras.layers.Input(shape=[IMG_HEIGHT, IMG_WIDTH,3], name='input_image')
  tar = tf.keras.layers.Input(shape=[IMG_HEIGHT, IMG_WIDTH,3], name='target_image')

  x = tf.keras.layers.concatenate([inp, tar])  # (batch_size, 256, 256, channels*2)

  down1 = downsample(64, 4, False)(x)  # (batch_size, 256, 256, 64)
  down2 = downsample(128, 4)(down1)  # (batch_size, 128, 128, 128)
  down3 = downsample(256, 4)(down2)  # (batch_size, 64, 64, 256)
  down4 = downsample(512, 4)(down3)
  down5 = downsample(512, 4)(down4)
  down6 = downsample(512, 4)(down5)
  down7 = downsample(512, 4)(down6)

  zero_pad1 = tf.keras.layers.ZeroPadding2D()(down7)  # (batch_size, 6, 6, 512)
  conv = tf.keras.layers.Conv2D(512, 4, strides=1,
                                kernel_initializer=initializer,
                                use_bias=False)(zero_pad1)  # (batch_size, 3, 3, 512)

  batchnorm1 = tf.keras.layers.BatchNormalization()(conv)

  leaky_relu = tf.keras.layers.LeakyReLU()(batchnorm1)

  zero_pad2 = tf.keras.layers.ZeroPadding2D()(leaky_relu)  # (batch_size, 5, 5, 512)

  last = tf.keras.layers.Conv2D(1, 4, strides=1,
                                kernel_initializer=initializer)(zero_pad2)  # (batch_size, 2, 2, 1)

  return tf.keras.Model(inputs=[inp, tar], outputs=last)

discriminator = Discriminator()




"""###Discriminator loss"""

def discriminator_loss(disc_real_output, disc_generated_output):
  real_loss = loss_object(tf.ones_like(disc_real_output), disc_real_output)

  generated_loss = loss_object(tf.zeros_like(disc_generated_output), disc_generated_output)

  total_disc_loss = real_loss + generated_loss

  return total_disc_loss

"""###OPTI"""

generator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)
discriminator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)

checkpoint_dir = './training_checkpoints'
checkpoint_prefix = os.path.join(checkpoint_dir, "ckpt")
checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,
                                 discriminator_optimizer=discriminator_optimizer,
                                 generator=generator,
                                 discriminator=discriminator)

def generate_images(model, test_input, tar):
  prediction = model(test_input, training=True)
  plt.figure(figsize=(15, 15))

  display_list = [test_input[0], tar[0], prediction[0]]
  title = ['Input Image', 'Ground Truth', 'Predicted Image']

  for i in range(3):
    plt.subplot(1, 3, i+1)
    plt.title(title[i])
    # Getting the pixel values in the [0, 1] range to plot.
    plt.imshow(display_list[i] * 0.5 + 0.5)
    plt.axis('off')
  plt.show()


log_dir="logs/"

summary_writer = tf.summary.create_file_writer(
  log_dir + "fit/" + datetime.datetime.now().strftime("%Y%m%d-%H%M%S"))

@tf.function
def train_step(input_image, target, step):
  with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:
    gen_output = generator(input_image, training=True)

    disc_real_output = discriminator([input_image, target], training=True)
    disc_generated_output = discriminator([input_image, gen_output], training=True)

    gen_total_loss, gen_gan_loss, gen_l1_loss = generator_loss(disc_generated_output, gen_output, target)
    disc_loss = discriminator_loss(disc_real_output, disc_generated_output)

  generator_gradients = gen_tape.gradient(gen_total_loss,
                                          generator.trainable_variables)
  discriminator_gradients = disc_tape.gradient(disc_loss,
                                               discriminator.trainable_variables)

  generator_optimizer.apply_gradients(zip(generator_gradients,
                                          generator.trainable_variables))
  discriminator_optimizer.apply_gradients(zip(discriminator_gradients,
                                              discriminator.trainable_variables))

  with summary_writer.as_default():
    tf.summary.scalar('gen_total_loss', gen_total_loss, step=step//1000)
    tf.summary.scalar('gen_gan_loss', gen_gan_loss, step=step//1000)
    tf.summary.scalar('gen_l1_loss', gen_l1_loss, step=step//1000)
    tf.summary.scalar('disc_loss', disc_loss, step=step//1000)

def fit(train_ds, test_ds, steps):
  example_input, example_target = next(iter(test_ds.take(1)))
  start = time.time()

  for step, (input_image, target) in train_ds.repeat().take(steps).enumerate():
    if (step) % 1000 == 0:
      display.clear_output(wait=True)

      if step != 0:
        print(f'Time taken for 1000 steps: {time.time()-start:.2f} sec\n')

      start = time.time()

      generate_images(generator, example_input, example_target)
      print(f"Step: {step//1000}k")

    train_step(input_image, target, step)

    # Training step
    if (step+1) % 10 == 0:
      print('.', end='', flush=True)


    # Save (checkpoint) the model every 5k steps
    if (step + 1) % 5000 == 0:
      checkpoint.save(file_prefix=checkpoint_prefix)

# Commented out IPython magic to ensure Python compatibility.
# %load_ext tensorboard
# %tensorboard --logdir {log_dir}


if __name__ == "__main__":

    fit(train_dataset, val_dataset, steps=40000)
    model.save("pix2pix")
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
